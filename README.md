# üê¶ Analyse des Sentiments sur Twitter avec Apache Spark

[![Python](https://img.shields.io/badge/python-3.10-blue)](https://www.python.org/)
[![PyPI](https://img.shields.io/pypi/v/pyspark)](https://pypi.org/project/pyspark/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---

## üåü Introduction
Ce projet consiste √† **analyser les sentiments des tweets** en utilisant **Apache Spark** pour le traitement distribu√© et le machine learning.  
Il inclut √©galement une **simulation de streaming** pour effectuer des pr√©dictions en temps r√©el.

---

## üìÅ Structure du projet

- `twitter-sentiment-analysis-spark-nlp.ipynb` : Notebook principal
- `twitter_training.csv` : Dataset (√† ajouter localement)
- `requirements.txt` : D√©pendances Python
- `.gitignore` : Fichiers ignor√©s par Git
- `LICENSE` :Licence MIT

---

## üõ†Ô∏è Installation

Cloner le d√©p√¥t :
git clone https://github.com/amenisahmim/-twitter-sentiment-analysis-bigdata.git

cd analyse-des-sentiments-twitter-bigdata

Installer les d√©pendances :
pip install -r requirements.txt

---

# üèóÔ∏è Workflow du projet - Analyse des Sentiments sur Twitter

---

## PARTIE 1 : Chargement et exploration des donn√©es massives
- Initialisation d'un environnement Spark distribu√©
- Lecture du fichier CSV `twitter_training.csv`
- Exploration distribu√©e : statistiques descriptives, distribution des sentiments
- Visualisation avec Matplotlib et Seaborn
- Identification des colonnes principales : `id`, `topic`, `sentiment`, `text`

---

## PARTIE 2 : Manipulation avanc√©e des DataFrames & Spark SQL
- **Nettoyage du texte :**
  - Transformation en minuscules
  - Suppression d'URLs, mentions, hashtags, emojis et caract√®res sp√©ciaux
  - Mots vides (stopwords) et lemmatisation
- Tokenisation et vectorisation (Bag-of-Words + TF-IDF)
- Analyses avec Spark SQL :
  - Distribution des sentiments et des sujets
  - Longueur moyenne des tweets par sentiment
- Visualisations avanc√©es : boxplots, WordClouds

---

## PARTIE 3 : Stockage distribu√© et performances
- Sauvegarde des donn√©es en JSON et Parquet
- Comparaison des performances : temps de lecture JSON vs Parquet
- Simulation d'un HDFS local pour stockage distribu√©

---

## PARTIE 4 : Machine Learning distribu√©
- Transformation des labels textuels en num√©riques
- Mod√®les entra√Æn√©s :
  - Bayes na√Øf
  - R√©gression logistique
  - Arbre de d√©cision
  - For√™t al√©atoire
- √âvaluation : pr√©cision, score F1
- Pipeline complet Spark ML pour NLP et classification distribu√©e

---

## PARTIE 5 : Streaming simul√© ‚Äì Pr√©diction en temps r√©el
- Simulation de flux de tweets r√©alistes
- Nettoyage et vectorisation en temps r√©el
- Pr√©diction de sentiment sur chaque tweet
- Affichage dynamique de la distribution des sentiments
- Export des r√©sultats en CSV et stockage simul√© HDFS

---

## üìä Visualisations
- Histogrammes de distribution des sentiments
- Boxplots de longueur de tweets par sentiment
- WordClouds des mots les plus fr√©quents
- Graphiques en streaming pour le suivi en temps r√©el

---

## ‚ö° Technologies utilis√©es
- Python 3.10
- Pandas, Matplotlib, Seaborn
- NLTK pour le NLP
- Scikit-learn pour ML classique
- Apache Spark pour traitement distribu√© et ML
- HDFS local pour stockage distribu√©
- WordCloud pour visualisation des mots fr√©quents

---

## üìù Auteur
**Amani Sahmim** ‚Äì √âtudiante en Ing√©nierie Syst√®mes Embarqu√©s & IoT

---

## üìÑ Licence
Ce projet est sous licence **MIT** ‚Äì voir le fichier [LICENSE](LICENSE)
